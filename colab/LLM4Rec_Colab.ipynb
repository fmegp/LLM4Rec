{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM4Rec - Colab Notebook\n",
        "\n",
        "This notebook runs the full CLLM4Rec pipeline on Colab:\n",
        "1. Training (content pretrain + iterative mutual training)\n",
        "2. Finetuning (recommendation head)\n",
        "3. Evaluation (Recall@20/40, NDCG@100)\n",
        "\n",
        "**Requirements:**\n",
        "- GPU runtime (Runtime → Change runtime type → GPU)\n",
        "- Hugging Face account (for GPT-2 model)\n",
        "- Weights & Biases account (for experiment tracking)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Colab widget manager enabled\n",
            "Cloning repository...\n"
          ]
        },
        {
          "ename": "CalledProcessError",
          "evalue": "Command '['git', 'clone', '--depth', '1', 'https://github.com/fmegp/LLM4Rec.git', '/content/LLM4Rec']' returned non-zero exit status 128.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1403424684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIN_COLAB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cloning repository...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"git\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--depth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREPO_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREPO_DIR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mIN_COLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'clone', '--depth', '1', 'https://github.com/fmegp/LLM4Rec.git', '/content/LLM4Rec']' returned non-zero exit status 128."
          ]
        }
      ],
      "source": [
        "# ====== Cell 1: Setup ======\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Enable Colab widget manager for tqdm progress bars\n",
        "try:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "    IN_COLAB = True\n",
        "    print(\"✓ Colab widget manager enabled\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Colab\")\n",
        "\n",
        "# Clone the repo\n",
        "REPO_URL = \"https://github.com/fmegp/LLM4Rec.git\"\n",
        "REPO_DIR = \"/content/LLM4Rec\"\n",
        "\n",
        "if IN_COLAB and not Path(REPO_DIR).exists():\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR], check=True)\n",
        "    os.chdir(REPO_DIR)\n",
        "elif IN_COLAB:\n",
        "    os.chdir(REPO_DIR)\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements-colab.txt\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ipywidgets>=8.1.0\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\"], check=True)\n",
        "\n",
        "# Add src to path\n",
        "src_path = str(Path(REPO_DIR if IN_COLAB else \".\").resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Verify tqdm works\n",
        "print(\"\\nTesting tqdm progress bar...\")\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "for _ in tqdm(range(10), desc=\"Test\", leave=True):\n",
        "    time.sleep(0.1)\n",
        "print(\"✓ tqdm working\")\n",
        "\n",
        "# Verify llm4rec imports\n",
        "from llm4rec.runtime import print_runtime_report\n",
        "print_runtime_report()\n",
        "print(\"\\n✓ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 2: Output Directory (Ephemeral) ======\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "RUN_ID = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTPUT_DIR = f\"/content/outputs/run_{RUN_ID}\"\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "print(f\"RUN_ID: {RUN_ID}\")\n",
        "print(\"\\nNote: This is ephemeral storage. Outputs will be lost when the runtime resets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 3: Hugging Face Login ======\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"Login to Hugging Face to download GPT-2 model.\")\n",
        "print(\"Get your token from: https://huggingface.co/settings/tokens\\n\")\n",
        "\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 4: Weights & Biases Login ======\n",
        "\n",
        "import wandb\n",
        "\n",
        "print(\"Login to Weights & Biases for experiment tracking.\")\n",
        "print(\"Get your API key from: https://wandb.ai/authorize\\n\")\n",
        "\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 5: Dataset Download + W&B Init ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.io import (\n",
        "    download_gdrive,\n",
        "    safe_extract_archive,\n",
        "    validate_dataset_layout,\n",
        "    build_dataset_manifest,\n",
        "    save_json,\n",
        ")\n",
        "from llm4rec.logging_wandb import WandbHandle\n",
        "\n",
        "# Dataset config\n",
        "DATASET_NAME = \"beauty\"  # Options: beauty, sports, toys\n",
        "LAMBDA_V = 1.0\n",
        "DATA_GDRIVE_URL = \"https://drive.google.com/file/d/1G4t64tzAlXN0gq_0TJ5Wik8dsERz8pMJ/view?usp=drive_link\"\n",
        "\n",
        "# Download and extract\n",
        "RAW_DIR = Path(\"/content/data/raw\")\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ARCHIVE_PATH = RAW_DIR / \"cllm4rec_dataset\"\n",
        "EXTRACT_DIR = RAW_DIR / \"extracted\"\n",
        "\n",
        "if not ARCHIVE_PATH.exists():\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_gdrive(DATA_GDRIVE_URL, ARCHIVE_PATH, quiet=False)\n",
        "else:\n",
        "    print(\"Dataset already downloaded\")\n",
        "\n",
        "if not EXTRACT_DIR.exists():\n",
        "    print(\"Extracting dataset...\")\n",
        "    EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    safe_extract_archive(ARCHIVE_PATH, EXTRACT_DIR)\n",
        "else:\n",
        "    print(\"Dataset already extracted\")\n",
        "\n",
        "# Find dataset directory\n",
        "candidates = [p.parent for p in EXTRACT_DIR.rglob(\"meta.pkl\")]\n",
        "match = next((c for c in candidates if c.name == DATASET_NAME), candidates[0] if len(candidates) == 1 else None)\n",
        "if match is None:\n",
        "    raise RuntimeError(f\"Dataset '{DATASET_NAME}' not found. Available: {[c.name for c in candidates]}\")\n",
        "\n",
        "DATASET_DIR = str(match)\n",
        "print(f\"\\nDATASET_DIR: {DATASET_DIR}\")\n",
        "\n",
        "# Validate\n",
        "layout = validate_dataset_layout(DATASET_DIR)\n",
        "print(f\"\\nDataset layout validated:\")\n",
        "print(f\"  - meta.pkl: {layout.meta_path}\")\n",
        "print(f\"  - train_matrix.npz: {layout.train_matrix_path}\")\n",
        "print(f\"  - review.pkl: {layout.review_path}\")\n",
        "\n",
        "# Initialize W&B run (wrap in WandbHandle for stage functions)\n",
        "print(\"\\nInitializing W&B run...\")\n",
        "_wandb_run = wandb.init(\n",
        "    project=\"cllm4rec\",\n",
        "    name=f\"{DATASET_NAME}_lambda{LAMBDA_V}_{RUN_ID}\",\n",
        "    config={\n",
        "        \"dataset_name\": DATASET_NAME,\n",
        "        \"lambda_V\": LAMBDA_V,\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"output_dir\": OUTPUT_DIR,\n",
        "    },\n",
        ")\n",
        "wandb_handle = WandbHandle(run=_wandb_run, enabled=True)\n",
        "print(f\"W&B run: {_wandb_run.url}\")\n",
        "\n",
        "# Save manifest\n",
        "manifest = build_dataset_manifest(DATASET_DIR, include_optional=True)\n",
        "save_json(manifest, Path(OUTPUT_DIR) / \"dataset_manifest.json\")\n",
        "print(f\"\\n✓ Dataset ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 6: Training ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.training_stage import run_training\n",
        "\n",
        "HF_MODEL_NAME = \"openai-community/gpt2\"\n",
        "HF_CACHE_DIR = \"/content/hf_cache\"\n",
        "\n",
        "training_out = Path(OUTPUT_DIR) / \"training\"\n",
        "content_user = training_out / \"content\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "collab_user = training_out / \"collaborative\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "\n",
        "if content_user.exists() and collab_user.exists():\n",
        "    print(f\"Training artifacts already exist at {training_out}\")\n",
        "    print(\"Skipping training stage.\")\n",
        "else:\n",
        "    print(\"Starting training stage...\\n\")\n",
        "    run_training(\n",
        "        dataset_dir=DATASET_DIR,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        lambda_V=LAMBDA_V,\n",
        "        hf_model_name=HF_MODEL_NAME,\n",
        "        hf_cache_dir=HF_CACHE_DIR,\n",
        "        hf_token=None,  # Uses cached HF login\n",
        "        mixed_precision=\"bf16\",\n",
        "        wandb_handle=wandb_handle,\n",
        "    )\n",
        "    print(\"\\n✓ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 7: Finetuning ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.finetune_stage import run_finetuning\n",
        "\n",
        "training_out = Path(OUTPUT_DIR) / \"training\"\n",
        "finetune_out = Path(OUTPUT_DIR) / \"finetuning\"\n",
        "rec_user = finetune_out / \"rec\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "\n",
        "if rec_user.exists():\n",
        "    print(f\"Finetuning artifacts already exist at {finetune_out}\")\n",
        "    print(\"Skipping finetuning stage.\")\n",
        "else:\n",
        "    print(\"Starting finetuning stage...\\n\")\n",
        "    run_finetuning(\n",
        "        dataset_dir=DATASET_DIR,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        pretrained_dir=str(training_out),\n",
        "        lambda_V=LAMBDA_V,\n",
        "        hf_model_name=HF_MODEL_NAME,\n",
        "        hf_cache_dir=HF_CACHE_DIR,\n",
        "        hf_token=None,\n",
        "        mixed_precision=\"bf16\",\n",
        "        wandb_handle=wandb_handle,\n",
        "    )\n",
        "    print(\"\\n✓ Finetuning complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 8: Evaluation ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.eval_stage import run_eval\n",
        "\n",
        "finetune_out = Path(OUTPUT_DIR) / \"finetuning\"\n",
        "\n",
        "print(\"Starting evaluation...\\n\")\n",
        "results = run_eval(\n",
        "    dataset_dir=DATASET_DIR,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    rec_embeddings_dir=str(finetune_out / \"rec\"),\n",
        "    lambda_V=LAMBDA_V,\n",
        "    hf_model_name=HF_MODEL_NAME,\n",
        "    hf_cache_dir=HF_CACHE_DIR,\n",
        "    hf_token=None,\n",
        "    wandb_handle=wandb_handle,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*50)\n",
        "for k, v in results.items():\n",
        "    if isinstance(v, float):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "# Finish W&B run\n",
        "wandb.finish()\n",
        "print(f\"\\n✓ Run complete! Results saved to {OUTPUT_DIR}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
