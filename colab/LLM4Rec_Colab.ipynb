{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM4Rec - Colab Notebook\n",
        "\n",
        "This notebook runs the full CLLM4Rec pipeline on Colab:\n",
        "1. Training (content pretrain + iterative mutual training)\n",
        "2. Finetuning (recommendation head)\n",
        "3. Evaluation (Recall@20/40, NDCG@100)\n",
        "\n",
        "**Requirements:**\n",
        "- GPU runtime (Runtime → Change runtime type → GPU)\n",
        "- Hugging Face account (for GPT-2 model)\n",
        "- Weights & Biases account (for experiment tracking)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Colab widget manager enabled\n",
            "Cloning repository...\n",
            "Working directory: /content/LLM4Rec\n",
            "Installing dependencies...\n",
            "\n",
            "Testing tqdm progress bar...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b64b3e01f9460f88d32314ec0f3c6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Test:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ tqdm working\n",
            "============================================================\n",
            "Runtime Report\n",
            "============================================================\n",
            "Python: 3.12.12\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Torch: 2.9.0+cpu\n",
            "CUDA available: False\n",
            "CUDA version: None\n",
            "GPU: None\n",
            "Numpy: 2.0.2\n",
            "\n",
            "✓ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# ====== Cell 1: Setup ======\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Enable Colab widget manager for tqdm progress bars\n",
        "try:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "    IN_COLAB = True\n",
        "    print(\"✓ Colab widget manager enabled\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Colab\")\n",
        "\n",
        "# Clone the repo\n",
        "REPO_URL = \"https://github.com/fmegp/LLM4Rec.git\"\n",
        "REPO_DIR = \"/content/LLM4Rec\"\n",
        "\n",
        "if IN_COLAB and not Path(REPO_DIR).exists():\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR], check=True)\n",
        "    os.chdir(REPO_DIR)\n",
        "elif IN_COLAB:\n",
        "    os.chdir(REPO_DIR)\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements-colab.txt\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ipywidgets>=8.1.0\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\"], check=True)\n",
        "\n",
        "# Add src to path\n",
        "src_path = str(Path(REPO_DIR if IN_COLAB else \".\").resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Verify tqdm works\n",
        "print(\"\\nTesting tqdm progress bar...\")\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "for _ in tqdm(range(10), desc=\"Test\", leave=True):\n",
        "    time.sleep(0.1)\n",
        "print(\"✓ tqdm working\")\n",
        "\n",
        "# Verify llm4rec imports\n",
        "from llm4rec.runtime import print_runtime_report\n",
        "print_runtime_report()\n",
        "print(\"\\n✓ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUTPUT_DIR: /content/outputs/run_20251219_164158\n",
            "RUN_ID: 20251219_164158\n",
            "\n",
            "Note: This is ephemeral storage. Outputs will be lost when the runtime resets.\n"
          ]
        }
      ],
      "source": [
        "# ====== Cell 2: Output Directory (Ephemeral) ======\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "RUN_ID = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTPUT_DIR = f\"/content/outputs/run_{RUN_ID}\"\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "print(f\"RUN_ID: {RUN_ID}\")\n",
        "print(\"\\nNote: This is ephemeral storage. Outputs will be lost when the runtime resets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Login to Hugging Face to download GPT-2 model.\n",
            "Get your token from: https://huggingface.co/settings/tokens\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3486446eaf274ba3957220df46b775b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ====== Cell 3: Hugging Face Login ======\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"Login to Hugging Face to download GPT-2 model.\")\n",
        "print(\"Get your token from: https://huggingface.co/settings/tokens\\n\")\n",
        "\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Login to Weights & Biases for experiment tracking.\n",
            "Get your API key from: https://wandb.ai/authorize\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfmenol\u001b[0m (\u001b[33mfmenol-csynbiosys\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ====== Cell 4: Weights & Biases Login ======\n",
        "\n",
        "import wandb\n",
        "\n",
        "print(\"Login to Weights & Biases for experiment tracking.\")\n",
        "print(\"Get your API key from: https://wandb.ai/authorize\\n\")\n",
        "\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Downloading Google Drive file id=1G4t64tzAlXN0gq_0TJ5Wik8dsERz8pMJ to /content/data/raw/cllm4rec_dataset ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1G4t64tzAlXN0gq_0TJ5Wik8dsERz8pMJ\n",
            "From (redirected): https://drive.google.com/uc?id=1G4t64tzAlXN0gq_0TJ5Wik8dsERz8pMJ&confirm=t&uuid=c3dbaf04-3a92-4a3a-b21a-562beb4154b5\n",
            "To: /content/data/raw/cllm4rec_dataset\n",
            "100%|██████████| 334M/334M [00:04<00:00, 72.7MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset...\n",
            "\n",
            "DATASET_DIR: /content/data/raw/extracted/data/beauty\n",
            "\n",
            "Dataset layout validated:\n",
            "  - meta.pkl: /content/data/raw/extracted/data/beauty/meta.pkl\n",
            "  - train_matrix.npz: /content/data/raw/extracted/data/beauty/train_matrix.npz\n",
            "  - review.pkl: /content/data/raw/extracted/data/beauty/user_item_texts/review.pkl\n",
            "\n",
            "Initializing W&B run...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/LLM4Rec/wandb/run-20251219_164353-12fmckni</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fmenol-csynbiosys/cllm4rec/runs/12fmckni' target=\"_blank\">beauty_lambda1.0_20251219_164158</a></strong> to <a href='https://wandb.ai/fmenol-csynbiosys/cllm4rec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fmenol-csynbiosys/cllm4rec' target=\"_blank\">https://wandb.ai/fmenol-csynbiosys/cllm4rec</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fmenol-csynbiosys/cllm4rec/runs/12fmckni' target=\"_blank\">https://wandb.ai/fmenol-csynbiosys/cllm4rec/runs/12fmckni</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W&B run: https://wandb.ai/fmenol-csynbiosys/cllm4rec/runs/12fmckni\n",
            "\n",
            "✓ Dataset ready!\n"
          ]
        }
      ],
      "source": [
        "# ====== Cell 5: Dataset Download + W&B Init ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.io import (\n",
        "    download_gdrive,\n",
        "    safe_extract_archive,\n",
        "    validate_dataset_layout,\n",
        "    build_dataset_manifest,\n",
        "    save_json,\n",
        ")\n",
        "from llm4rec.logging_wandb import WandbHandle\n",
        "\n",
        "# Dataset config\n",
        "DATASET_NAME = \"beauty\"  # Options: beauty, sports, toys\n",
        "LAMBDA_V = 1.0\n",
        "DATA_GDRIVE_URL = \"https://drive.google.com/file/d/1G4t64tzAlXN0gq_0TJ5Wik8dsERz8pMJ/view?usp=drive_link\"\n",
        "\n",
        "# Download and extract\n",
        "RAW_DIR = Path(\"/content/data/raw\")\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ARCHIVE_PATH = RAW_DIR / \"cllm4rec_dataset\"\n",
        "EXTRACT_DIR = RAW_DIR / \"extracted\"\n",
        "\n",
        "if not ARCHIVE_PATH.exists():\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_gdrive(DATA_GDRIVE_URL, ARCHIVE_PATH, quiet=False)\n",
        "else:\n",
        "    print(\"Dataset already downloaded\")\n",
        "\n",
        "if not EXTRACT_DIR.exists():\n",
        "    print(\"Extracting dataset...\")\n",
        "    EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    safe_extract_archive(ARCHIVE_PATH, EXTRACT_DIR)\n",
        "else:\n",
        "    print(\"Dataset already extracted\")\n",
        "\n",
        "# Find dataset directory\n",
        "candidates = [p.parent for p in EXTRACT_DIR.rglob(\"meta.pkl\")]\n",
        "match = next((c for c in candidates if c.name == DATASET_NAME), candidates[0] if len(candidates) == 1 else None)\n",
        "if match is None:\n",
        "    raise RuntimeError(f\"Dataset '{DATASET_NAME}' not found. Available: {[c.name for c in candidates]}\")\n",
        "\n",
        "DATASET_DIR = str(match)\n",
        "print(f\"\\nDATASET_DIR: {DATASET_DIR}\")\n",
        "\n",
        "# Validate\n",
        "layout = validate_dataset_layout(DATASET_DIR)\n",
        "print(f\"\\nDataset layout validated:\")\n",
        "print(f\"  - meta.pkl: {layout.meta_path}\")\n",
        "print(f\"  - train_matrix.npz: {layout.train_matrix_path}\")\n",
        "print(f\"  - review.pkl: {layout.review_path}\")\n",
        "\n",
        "# Initialize W&B run (wrap in WandbHandle for stage functions)\n",
        "print(\"\\nInitializing W&B run...\")\n",
        "_wandb_run = wandb.init(\n",
        "    project=\"cllm4rec\",\n",
        "    name=f\"{DATASET_NAME}_lambda{LAMBDA_V}_{RUN_ID}\",\n",
        "    config={\n",
        "        \"dataset_name\": DATASET_NAME,\n",
        "        \"lambda_V\": LAMBDA_V,\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"output_dir\": OUTPUT_DIR,\n",
        "    },\n",
        ")\n",
        "wandb_handle = WandbHandle(run=_wandb_run, enabled=True)\n",
        "print(f\"W&B run: {_wandb_run.url}\")\n",
        "\n",
        "# Save manifest\n",
        "manifest = build_dataset_manifest(DATASET_DIR, include_optional=True)\n",
        "save_json(manifest, Path(OUTPUT_DIR) / \"dataset_manifest.json\")\n",
        "print(f\"\\n✓ Dataset ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training stage...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e302a15eb47e41e79680e626003fcc21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97e6580c42cc42a7815a05a62762c3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e7e233a1e84fc2ab6441b74d21c261",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "729a48f9ddc6430ea4f834245ac02012",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "313bae36cb95486ab5ffc8ee49693ebf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aecf3fcf1dc485989e9b52cb563c187",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Begin Content GPT Pretraining Loop-----\n",
            "============================================================\n",
            "Content GPT Pretraining - Epoch 1/10\n",
            "============================================================\n",
            "Loading first batch (tokenization may take a while)...\n"
          ]
        }
      ],
      "source": [
        "# ====== Cell 6: Training ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.training_stage import run_training\n",
        "\n",
        "HF_MODEL_NAME = \"openai-community/gpt2\"\n",
        "HF_CACHE_DIR = \"/content/hf_cache\"\n",
        "\n",
        "training_out = Path(OUTPUT_DIR) / \"training\"\n",
        "content_user = training_out / \"content\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "collab_user = training_out / \"collaborative\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "\n",
        "if content_user.exists() and collab_user.exists():\n",
        "    print(f\"Training artifacts already exist at {training_out}\")\n",
        "    print(\"Skipping training stage.\")\n",
        "else:\n",
        "    print(\"Starting training stage...\\n\")\n",
        "    run_training(\n",
        "        dataset_dir=DATASET_DIR,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        lambda_V=LAMBDA_V,\n",
        "        hf_model_name=HF_MODEL_NAME,\n",
        "        hf_cache_dir=HF_CACHE_DIR,\n",
        "        hf_token=None,  # Uses cached HF login\n",
        "        mixed_precision=\"bf16\",\n",
        "        wandb_handle=wandb_handle,\n",
        "    )\n",
        "    print(\"\\n✓ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 7: Finetuning ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.finetune_stage import run_finetuning\n",
        "\n",
        "training_out = Path(OUTPUT_DIR) / \"training\"\n",
        "finetune_out = Path(OUTPUT_DIR) / \"finetuning\"\n",
        "rec_user = finetune_out / \"rec\" / f\"user_embeddings_{LAMBDA_V}.pt\"\n",
        "\n",
        "if rec_user.exists():\n",
        "    print(f\"Finetuning artifacts already exist at {finetune_out}\")\n",
        "    print(\"Skipping finetuning stage.\")\n",
        "else:\n",
        "    print(\"Starting finetuning stage...\\n\")\n",
        "    run_finetuning(\n",
        "        dataset_dir=DATASET_DIR,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        pretrained_dir=str(training_out),\n",
        "        lambda_V=LAMBDA_V,\n",
        "        hf_model_name=HF_MODEL_NAME,\n",
        "        hf_cache_dir=HF_CACHE_DIR,\n",
        "        hf_token=None,\n",
        "        mixed_precision=\"bf16\",\n",
        "        wandb_handle=wandb_handle,\n",
        "    )\n",
        "    print(\"\\n✓ Finetuning complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Cell 8: Evaluation ======\n",
        "\n",
        "from pathlib import Path\n",
        "from llm4rec.stages.eval_stage import run_eval\n",
        "\n",
        "finetune_out = Path(OUTPUT_DIR) / \"finetuning\"\n",
        "\n",
        "print(\"Starting evaluation...\\n\")\n",
        "results = run_eval(\n",
        "    dataset_dir=DATASET_DIR,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    rec_embeddings_dir=str(finetune_out / \"rec\"),\n",
        "    lambda_V=LAMBDA_V,\n",
        "    hf_model_name=HF_MODEL_NAME,\n",
        "    hf_cache_dir=HF_CACHE_DIR,\n",
        "    hf_token=None,\n",
        "    wandb_handle=wandb_handle,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*50)\n",
        "for k, v in results.items():\n",
        "    if isinstance(v, float):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "# Finish W&B run\n",
        "wandb.finish()\n",
        "print(f\"\\n✓ Run complete! Results saved to {OUTPUT_DIR}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
